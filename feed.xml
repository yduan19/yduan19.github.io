<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://19revey.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://19revey.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-24T18:23:59+00:00</updated><id>https://19revey.github.io/feed.xml</id><title type="html">Yifei Duan</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">UV - Fast Python Package Manager</title><link href="https://19revey.github.io/blog/2025/uv/" rel="alternate" type="text/html" title="UV - Fast Python Package Manager"/><published>2025-03-10T08:13:00+00:00</published><updated>2025-03-10T08:13:00+00:00</updated><id>https://19revey.github.io/blog/2025/uv</id><content type="html" xml:base="https://19revey.github.io/blog/2025/uv/"><![CDATA[<p><br/></p> <h3 id="install-uv">Install UV</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># On macOS and Linux</span>
curl <span class="nt">-LsSf</span> https://astral.sh/uv/install.sh | sh

<span class="c"># On Windows</span>
powershell <span class="nt">-ExecutionPolicy</span> ByPass <span class="nt">-c</span> <span class="s2">"irm https://astral.sh/uv/install.ps1 | iex"</span>

<span class="c"># Using pip</span>
pip <span class="nb">install </span>uv

<span class="c"># Using pipx</span>
pipx <span class="nb">install </span>uv
</code></pre></div></div> <p><br/></p> <h3 id="project-management">Project Management</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Initialize a new project</span>
uv init example
<span class="nb">cd </span>example


<span class="c"># Add dependencies</span>
uv add ruff
uv add requests pandas

<span class="c"># Create/update lockfile</span>
uv lock

<span class="c"># Sync dependencies from lockfile</span>
uv <span class="nb">sync</span>
</code></pre></div></div> <p><br/></p> <h3 id="tool-management">Tool Management</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run tool in ephemeral environment</span>
uvx pycowsay <span class="s1">'hello world!'</span>

<span class="c"># Install tool permanently</span>
uv tool <span class="nb">install </span>ruff

<span class="c"># Run installed tool</span>
ruff <span class="nt">--version</span>
</code></pre></div></div> <p><br/></p> <h3 id="script-management">Script Management</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Add dependencies to a script</span>
uv add <span class="nt">--script</span> example.py requests

<span class="c"># Run script in isolated environment</span>
uv run example.py
</code></pre></div></div> <p><br/></p> <h3 id="python-version-management">Python Version Management</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install Python versions</span>
uv python <span class="nb">install </span>3.10 3.11 3.12

<span class="c"># Create venv with specific Python version</span>
uv venv <span class="nt">--python</span> 3.12.0

<span class="c"># Pin Python version for project</span>
uv python pin 3.11
</code></pre></div></div> <p><br/></p> <h3 id="pip-interface-commands">Pip Interface Commands</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Compile requirements</span>
uv pip compile requirements.in <span class="nt">--output-file</span> requirements.txt

<span class="c"># Create virtual environment</span>
uv venv

<span class="c"># Install from requirements</span>
uv pip <span class="nb">sync </span>requirements.txt
</code></pre></div></div> <table> <thead> <tr> <th>Command</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">uv init &lt;name&gt;</code></td> <td>Initialize new project</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">uv add &lt;package&gt;</code></td> <td>Add dependency to project</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">uv lock</code></td> <td>Generate lockfile</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">uv sync</code></td> <td>Install from lockfile</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">uv run &lt;script&gt;</code></td> <td>Run Python script</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">uv venv</code></td> <td>Create virtual environment</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">uvx &lt;tool&gt;</code></td> <td>Run tool in ephemeral env</td> </tr> </tbody> </table> <p>UV is an extremely fast Python package and project manager written in Rust. It aims to replace multiple tools like pip, pip-tools, pipx, poetry, pyenv, and virtualenv with a single unified solution. The tool offers 10-100x faster performance compared to pip and includes features like universal lockfiles, workspace support, and global dependency deduplication.</p>]]></content><author><name></name></author><category term="computer_science"/><category term="python"/><category term="package-manager"/><category term="rust"/><summary type="html"><![CDATA[Guide to using UV package manager for Python]]></summary></entry><entry><title type="html">Physics Informed Neural Network</title><link href="https://19revey.github.io/blog/2024/pinn/" rel="alternate" type="text/html" title="Physics Informed Neural Network"/><published>2024-03-20T12:57:00+00:00</published><updated>2024-03-20T12:57:00+00:00</updated><id>https://19revey.github.io/blog/2024/pinn</id><content type="html" xml:base="https://19revey.github.io/blog/2024/pinn/"><![CDATA[ <h2 style="color:purple;font-size: 2em;">Overview</h2> <ul> <li><a href="#section1">1. Introduction</a></li> <li><a href="#section2">2. Neural Netowork</a></li> <li><a href="#section3">3. Model Training</a></li> <li><a href="#section4">4. Results</a></li> <li><a href="#section5">5. Improvements</a></li> </ul> <h5 id="links-to-run-the-code">Links to run the code</h5> <ul> <li><a href="https://colab.research.google.com/github/19revey/PINN_granular_segregation/blob/main/notebook/solver_segregation.ipynb">Google colab</a></li> <li><a href="https://github.com/19revey/PINN_granular_segregation">Github repo</a></li> </ul> <h5 id="understand-the-granular-segregation-and-the-transport-equation">Understand the granular segregation and the transport equation</h5> <ul> <li><a href="https://arxiv.org/pdf/2309.13273.pdf">[1] General Model For Segregation Forces in Flowing Granular Mixtures</a></li> <li><a href="https://arxiv.org/pdf/1809.08089.pdf">[2] Diffusion, mixing, and segregation in confined granular flows</a></li> <li><a href="https://pubs.acs.org/doi/10.1021/acs.iecr.5b01268">[3] On Mixing and Segregation: From Fluids and Maps to Granular Solids and Advection–Diffusion Systems</a></li> </ul> <h5 id="pinn-implementation">PINN implementation</h5> <ul> <li><a href="https://github.com/nanditadoloi/PINN">https://github.com/nanditadoloi/PINN</a></li> <li><a href="https://github.com/omniscientoctopus/Physics-Informed-Neural-Networks">https://github.com/omniscientoctopus/Physics-Informed-Neural-Networks</a></li> <li><a href="https://github.com/maziarraissi/PINNs">https://github.com/maziarraissi/PINNs</a></li> </ul> <p>Here is a li</p> <p><a class="anchor" id="section1"></a></p> <h2 style="color:purple;font-size: 2em;">1. Introduction</h2> <p>An advection-diffusion transport equation has been successfully used to model the segregation. Within this continuum framework, the concentration of species \(i\) can be expressed as</p> \[\frac{\partial c_i}{\partial t} + {\nabla \cdot (\pmb u c_i)}={\nabla \cdot (D\nabla c_i)}.\] <p>With assumption of incompressible flow and negligible vertical acceleration, the above equation in the \(z\) direction can be written as</p> \[\frac{\partial c_i}{\partial t} +\frac{\partial (w+w_{i})c_i}{\partial z}=\frac{\partial}{\partial z} \Big( D\frac{\partial c_i}{\partial z} \Big),\] <p>or, rearranging, as</p> \[w_{i}c_i-D\frac{\partial c_i}{\partial z}=0,\] <p>where \(w_{i}\) is the segregation velocity relative to the bulk velocity \(w\).</p> <table> <thead> <tr> <th> </th> <th> </th> <th>full model</th> <th>simplified model</th> </tr> </thead> <tbody> <tr> <td>intruder scaled segregation force</td> <td>\(F_{i,0}\)</td> <td>\(-f^g(R)\frac{\partial{p}}{\partial{z}}V_i+f^k(R)\frac{p}{\dot\gamma}\frac{\partial\dot\gamma}{\partial{z}}V_i\)</td> <td> </td> </tr> <tr> <td>Mixture scaled segregation force</td> <td>\(\hat F_{l}\) <br/> \(\hat{F}_{s}\)</td> <td>\((\hat{F}_{l,0}-\cos{\theta})\textrm{tanh}\Big( \frac{\cos{\theta}-\hat{F}_{s,0}}{\hat{F}_{l,0}-\cos{\theta}}\frac{c_s}{c_l} \Big)\) <br/> \(-(\hat{F}_{l,0}-\cos{\theta}){\frac{c_l}{c_s}}\textrm{tanh}\Big( \frac{\cos{\theta}-\hat{F}_{s,0}}{\hat{F}_{l,0}-\cos{\theta}}\frac{c_s}{c_l} \Big)\)</td> <td> </td> </tr> <tr> <td>effective friction</td> <td>\(\mu_{eff}\)</td> <td>\(\mu_s+\frac{\mu_2-\mu_s}{I_c/I+1}\)</td> <td> </td> </tr> <tr> <td>viscosity</td> <td>\(\eta\)</td> <td>\(\mu_{eff} \frac{P}{\dot\gamma}\)</td> <td> </td> </tr> <tr> <td>drag coefficient</td> <td>\(c_{d,l}\) <br/> \(c_{d,s}\)</td> <td>\([k_1-k_2\exp(-k_3 R)]+s_1 I R +s_2 I (R_\rho-1)\) <br/> \(c_{d,l}/R^2\)</td> <td> </td> </tr> <tr> <td>segregation velocity</td> <td>\(w_l\) <br/> \(w_s\)</td> <td>\(\frac{ \hat F_{l} m_l g_0}{c_{d,l} \pi \eta d_l}\) <br/> \(-\frac{ \hat F_s m_s g_0}{c_{d,s} \pi \eta d_s}\)</td> <td>\(0.26 d_s \ln R \dot\gamma (1-c_i)\)</td> </tr> <tr> <td>diffusion coefficient</td> <td>\(D\)</td> <td>\(0.042 \dot \gamma (c_ld_l+c_sd_s)^2\)</td> <td>\(0.042 \dot \gamma {\bar d}^2\)</td> </tr> </tbody> </table> <p><a class="anchor" id="section2"></a></p> <h2 style="color:purple;font-size: 2em;">2. Physics Informed Neural Network</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">math</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="n">device</span> <span class="o">=</span> <span class="p">(</span>
    <span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
    <span class="k">else</span> <span class="sh">"</span><span class="s">mps</span><span class="sh">"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
    <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span>
<span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>

        <span class="c1"># 6 layer neural network
</span>        <span class="nf">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ln1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ln2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ln3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ln4</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">hidden_layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_layer3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_layer4</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_layer5</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mse</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>
        
        <span class="c1"># particle properties in S.I unit
</span>        <span class="n">self</span><span class="p">.</span><span class="n">rd</span><span class="o">=</span><span class="mi">2</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dl</span><span class="o">=</span><span class="mf">0.004</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rho</span><span class="o">=</span><span class="mi">1000</span>
        <span class="n">self</span><span class="p">.</span><span class="n">c_diffusion</span><span class="o">=</span><span class="mf">0.042</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ds</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dl</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">rd</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rds</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">rd</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ml</span><span class="o">=</span><span class="mi">4</span><span class="o">/</span><span class="mi">3</span><span class="o">*</span><span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="o">*</span><span class="mf">0.002</span><span class="o">**</span><span class="mi">3</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">rho</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ms</span><span class="o">=</span><span class="mi">4</span><span class="o">/</span><span class="mi">3</span><span class="o">*</span><span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="o">*</span><span class="mf">0.001</span><span class="o">**</span><span class="mi">3</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">rho</span>
        
        
        <span class="c1"># flow configuration (uniform shear)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">gamma</span><span class="o">=</span><span class="mi">100</span>
        <span class="n">self</span><span class="p">.</span><span class="n">phi</span><span class="o">=</span><span class="mf">0.55</span>
        <span class="n">self</span><span class="p">.</span><span class="n">g</span><span class="o">=</span><span class="mf">9.81</span>
        <span class="n">self</span><span class="p">.</span><span class="n">h0</span><span class="o">=</span><span class="mf">0.01</span>
        <span class="n">self</span><span class="p">.</span><span class="n">p0</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">h0</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">rho</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">g</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">phi</span>

        <span class="c1"># segregation force calculation
</span>        <span class="n">self</span><span class="p">.</span><span class="n">theta</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  
        <span class="c1">#  Duan et al. 2024
</span>        <span class="n">_intruder_l</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mf">1.43</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">rd</span><span class="o">/</span><span class="mf">0.92</span><span class="p">))</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mf">3.55</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">rd</span><span class="o">/</span><span class="mf">2.94</span><span class="p">))</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">phi</span>
        <span class="n">_intruder_s</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mf">1.43</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">rds</span><span class="o">/</span><span class="mf">0.92</span><span class="p">))</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mf">3.55</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">rds</span><span class="o">/</span><span class="mf">2.94</span><span class="p">))</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">phi</span>

        <span class="n">self</span><span class="p">.</span><span class="n">intruder_l</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">_intruder_l</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">intruder_s</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">_intruder_s</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="c1"># if time dimensino is considered, concatenated first, i.e. torch.cat([z,t],axis=1) 
</span>        <span class="n">layer1_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">ln1</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">hidden_layer1</span><span class="p">(</span><span class="n">z</span><span class="p">)))</span>
        <span class="n">layer2_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">ln2</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">hidden_layer2</span><span class="p">(</span><span class="n">layer1_out</span><span class="p">)))</span>
        <span class="n">layer3_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">ln3</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">hidden_layer3</span><span class="p">(</span><span class="n">layer2_out</span><span class="p">)))</span>
        <span class="n">layer4_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">ln4</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">hidden_layer4</span><span class="p">(</span><span class="n">layer3_out</span><span class="p">)))</span>
        <span class="n">layer5_out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">hidden_layer5</span><span class="p">(</span><span class="n">layer4_out</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">output_layer</span><span class="p">(</span><span class="n">layer5_out</span><span class="p">)</span> <span class="c1">## For regression, no activation is used in output layer
</span>        <span class="k">return</span> <span class="n">output</span>
    
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>


        <span class="c1"># PDE loss    
</span>        <span class="n">z_collocation</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10001</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">z_collocation</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 

        <span class="n">c</span> <span class="o">=</span> <span class="nf">self</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> 
        
        <span class="n">p</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">rho</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">phi</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">g</span><span class="o">*</span><span class="n">z</span><span class="o">+</span><span class="n">self</span><span class="p">.</span><span class="n">p0</span>
        <span class="n">inert</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">gamma</span><span class="o">*</span><span class="p">(</span><span class="n">c</span><span class="o">*</span><span class="mf">0.004</span><span class="o">+</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">c</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mf">0.004</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">rd</span><span class="p">))</span><span class="o">/</span><span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">rho</span><span class="p">);</span>
        <span class="n">mu_eff</span><span class="o">=</span><span class="mf">0.364</span><span class="o">+</span><span class="p">(</span><span class="mf">0.772</span><span class="o">-</span><span class="mf">0.364</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mf">0.434</span><span class="o">/</span><span class="n">inert</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">eta</span><span class="o">=</span><span class="n">mu_eff</span><span class="o">*</span><span class="n">p</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">gamma</span>

        <span class="n">mixture_l</span><span class="o">=</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">intruder_l</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">theta</span><span class="p">)</span><span class="o">*</span><span class="n">torch</span><span class="p">.</span><span class="nf">tanh</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">theta</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">intruder_s</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">intruder_l</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">theta</span><span class="p">)</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">ml</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">ms</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">c</span><span class="p">)</span><span class="o">/</span><span class="n">c</span><span class="p">)</span>
        <span class="n">mixture_s</span><span class="o">=-</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">intruder_l</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">theta</span><span class="p">)</span><span class="o">*</span><span class="n">c</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">c</span><span class="p">)</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">ms</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">ml</span><span class="o">*</span><span class="n">torch</span><span class="p">.</span><span class="nf">tanh</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">theta</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">intruder_s</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">intruder_l</span><span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">theta</span><span class="p">)</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">ml</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">ms</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">c</span><span class="p">)</span><span class="o">/</span><span class="n">c</span><span class="p">)</span>
        

        <span class="n">cd</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">-</span><span class="mi">7</span><span class="o">*</span><span class="n">math</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">2.6</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">rd</span><span class="p">))</span><span class="o">+</span><span class="mf">0.57</span><span class="o">*</span><span class="n">inert</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">rd</span>

        <span class="n">wseg</span><span class="o">=</span><span class="n">mixture_l</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">ml</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">g</span> <span class="o">/</span> <span class="p">(</span><span class="n">cd</span><span class="o">*</span><span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="o">*</span><span class="n">eta</span><span class="o">*</span><span class="mf">0.004</span><span class="p">)</span>

        <span class="n">c_z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="nf">grad</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="nf">sum</span><span class="p">(),</span> <span class="n">z</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Duan et al. 2024  
</span>        <span class="n">pde</span><span class="o">=</span><span class="p">(</span><span class="n">wseg</span><span class="o">*</span><span class="n">c</span><span class="o">-</span><span class="mf">0.042</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">gamma</span><span class="o">*</span><span class="n">torch</span><span class="p">.</span><span class="nf">square</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">c</span><span class="p">)</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">ds</span><span class="o">+</span><span class="n">c</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">dl</span><span class="p">)</span><span class="o">*</span><span class="n">c_z</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>

        <span class="c1"># Schlick et al. 2015
</span>        <span class="c1"># simplified with constant diffusion coefficient
</span>        <span class="c1"># pde = (1/0.1 *(1-c)*c - c_z )*10
</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">pde</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">pde_loss</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">mse</span><span class="p">(</span><span class="n">pde</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>


        <span class="c1"># Mass conservation loss
</span>        <span class="n">x_bc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">10001</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">x_bc</span> <span class="o">=</span> <span class="n">x_bc</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">u_bc</span> <span class="o">=</span> <span class="nf">self</span><span class="p">(</span><span class="n">x_bc</span><span class="p">)</span>
        <span class="n">u_bc</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">u_bc</span><span class="p">)</span>
        
        <span class="n">target</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">u_bc</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">+</span><span class="mf">0.5</span>
        <span class="n">mass_loss</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">mse</span><span class="p">(</span><span class="n">u_bc</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>
   
        <span class="k">return</span> <span class="n">mass_loss</span>  <span class="o">+</span> <span class="n">pde_loss</span>
</code></pre></div></div> <p><a class="anchor" id="section3"></a></p> <h2 style="color:purple;font-size: 2em;">3. Train </h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">net</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">mse_cost_function</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span> <span class="c1"># Mean squared error
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.002</span><span class="p">)</span>


<span class="n">iterations</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">previous_validation_loss</span> <span class="o">=</span> <span class="mf">99999999.0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span> <span class="c1"># to make the gradients zero
</span>    <span class="n">loss</span><span class="o">=</span><span class="n">net</span><span class="p">.</span><span class="nf">loss</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span> <span class="c1"># This is for computing gradients using backward propagation
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span> <span class="c1"># This is equivalent to : theta_new = theta_old - alpha * derivative of J w.r.t theta
</span>    <span class="k">if</span> <span class="n">loss</span><span class="p">.</span><span class="n">data</span><span class="o">&lt;</span><span class="mf">1e-6</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    	<span class="nf">print</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="sh">"</span><span class="s">Traning Loss:</span><span class="sh">"</span><span class="p">,</span><span class="n">loss</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div> <p><a class="anchor" id="section4"></a></p> <h2 style="color:purple;font-size: 2em;">4. Results </h2> <p>The full model prediction is compared to the previous model by Schlick et al. 2015 with different values of \(\lambda\).</p> \[\frac{d_c}{d_z}=\frac{1}{\lambda}c_l(1-c_l)\] <h2 style="color:purple;font-size: 1em;">4.1 Uniform shear </h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_img/comparison001-480.webp 480w,/assets/img/blog_img/comparison001-800.webp 800w,/assets/img/blog_img/comparison001-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog_img/comparison001.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_img/comparison01-480.webp 480w,/assets/img/blog_img/comparison01-800.webp 800w,/assets/img/blog_img/comparison01-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog_img/comparison01.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 style="color:purple;font-size: 1em;">4.2 Exponential shear </h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_img/comparison001exp-480.webp 480w,/assets/img/blog_img/comparison001exp-800.webp 800w,/assets/img/blog_img/comparison001exp-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog_img/comparison001exp.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_img/comparison01exp-480.webp 480w,/assets/img/blog_img/comparison01exp-800.webp 800w,/assets/img/blog_img/comparison01exp-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog_img/comparison01exp.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><a class="anchor" id="section5"></a></p> <h2 style="color:purple;font-size: 2em;">5. Improvements </h2> <ul> <li>Add loss function for \(c\) out of range 0 to 1</li> <li>Add a learning rate scheduler to reduce learning rate at loss plateau (lr reduced from 1e-3 to 1e-5)</li> </ul> <p>After these changes, the overall loss is reduced to 1e-8</p> <h2 style="color:purple;font-size: 1em;">5.1 Exponential shear </h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_img/comparison001exp_a-480.webp 480w,/assets/img/blog_img/comparison001exp_a-800.webp 800w,/assets/img/blog_img/comparison001exp_a-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog_img/comparison001exp_a.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog_img/comparison01exp_a-480.webp 480w,/assets/img/blog_img/comparison01exp_a-800.webp 800w,/assets/img/blog_img/comparison01exp_a-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog_img/comparison01exp_a.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div>]]></content><author><name></name></author><category term="machine_learning"/><summary type="html"><![CDATA[PINN for solving segregation problem]]></summary></entry><entry><title type="html">PINN for 2D segregation</title><link href="https://19revey.github.io/blog/2024/2dpinn/" rel="alternate" type="text/html" title="PINN for 2D segregation"/><published>2024-03-20T12:57:00+00:00</published><updated>2024-03-20T12:57:00+00:00</updated><id>https://19revey.github.io/blog/2024/2dpinn</id><content type="html" xml:base="https://19revey.github.io/blog/2024/2dpinn/"><![CDATA[ <h5 id="understand-the-granular-segregation-and-the-transport-equation">Understand the granular segregation and the transport equation</h5> <ul> <li><a href="https://arxiv.org/pdf/2309.13273.pdf">[1] General Model For Segregation Forces in Flowing Granular Mixtures</a></li> <li><a href="https://arxiv.org/pdf/1809.08089.pdf">[2] Diffusion, mixing, and segregation in confined granular flows</a></li> <li><a href="https://pubs.acs.org/doi/10.1021/acs.iecr.5b01268">[3] On Mixing and Segregation: From Fluids and Maps to Granular Solids and Advection–Diffusion Systems</a></li> </ul> <h2 id="introduction-">Introduction <a name="intro"></a></h2> <p>In this project, a PINN is trained to solve a 2D advection-segregation-diffusion problem.</p> \[\frac{\partial c_i}{\partial t} +\frac{\partial (w_{i}c_i)}{\partial z}=\frac{\partial}{\partial z} \Big( D\frac{\partial c_i}{\partial z} \Big),\] <p>with the following boundary conditions: \(\begin{cases} c_i(t=0, z) = 0.5 \\ w_{i}c_i|_{(t, z=0)}-D\frac{\partial c_i}{\partial z} |_{(t, z=H)} =0\\ w_{i}c_i|_{(t, z=0)}-D\frac{\partial c_i}{\partial z} |_{(t, z=H)}=0\\ \end{cases}\)<br/> The objective is to predict the transient concentration profile:</p> <p align="center"> <img src="/assets/img/proj_pinn/dem.png" alt="Description of the image" style="width: 50%;"/> </p> <h2 id="simplified-advection-diffusion-segregation">Simplified Advection-Diffusion-Segregation</h2> <p>Sample the domain with data points and build a Neural Network to minimize the loss function:</p> \[Loss_{domain}=\frac{\partial c_i}{\partial t} +\frac{\partial (w_{i}c_i)}{\partial z} -\frac{\partial}{\partial z} \Big( D\frac{\partial c_i}{\partial z} \Big),\] <p>Loss function for boundary data points:</p> \[Loss_{BC}=(w_{i}c_i) - D\frac{\partial c_i}{\partial z}.\] <p align="center"> <img src="/assets/img/proj_pinn/collocation.png" alt="Description of the image" style="width: 50%;"/> </p> <h3 id="linear-segregation">Linear Segregation</h3> <p>Assuming linear segregation velocity (Fan et al. 2014) and constant diffusion coefficient. \(\begin{cases} w_i=A\dot\gamma(1-c_i)\\ D=0.042\dot\gamma d^2\\ \end{cases}\)</p> <p>Large particle concentration profiles:</p> <p align="center"> <img src="/assets/img/proj_pinn/c_pinn.png" alt="Description of the image" style="width: 50%;"/> </p> <p align="center"> <img src="/assets/img/proj_pinn/c_profiles.png" alt="Description of the image" style="width: 100%;"/> </p> <h3 id="pressure-corrected-linear-segregation">Pressure-corrected Linear Segregation</h3> <p>Assuming linear segregation velocity (Fan et al. 2014) and constant diffusion coefficient. \(\begin{equation} \begin{cases} w_i=A\dot\gamma(1-c_i) \sqrt{\frac{P_0}{P}}\\ D=0.042\dot\gamma d^2\\ \end{cases} \end{equation}\)</p> <p>Large particle concentration profiles:</p> <p align="center"> <img src="/assets/img/proj_pinn/c_1_pinn.png" alt="Description of the image" style="width: 50%;"/> </p> <p align="center"> <img src="/assets/img/proj_pinn/c_1_profiles.png" alt="Description of the image" style="width: 100%;"/> </p> <h3 id="pressure-corrected-linear-segregation--concentration-dependent-diffusion-coefficient">Pressure-corrected Linear Segregation + concentration dependent diffusion coefficient</h3> <p>Assuming linear segregation velocity (Fan et al. 2014) and constant diffusion coefficient. \(\begin{equation} \begin{cases} w_i=A\dot\gamma(1-c_i) \sqrt{\frac{P_0}{P}}\\ D=0.042\dot\gamma (\sum c_id_i)^2\\ \end{cases} \end{equation}\)</p> <p>Large particle concentration profiles:</p> <p align="center"> <img src="/assets/img/proj_pinn/c_2_pinn.png" alt="Description of the image" style="width: 50%;"/> </p> <p align="center"> <img src="/assets/img/proj_pinn/c_2_profiles.png" alt="Description of the image" style="width: 100%;"/> </p> <h1 id="dem-informed-nn">DEM-informed NN</h1> <p>DEM simulations (\(R_d=2,~R_\rho=1,~t=37\,s\)):</p> <p align="center"> <img src="/assets/img/proj_pinn/dem_simulation.png" alt="Description of the image" style="width: 70%;"/> </p> <p>Segregation flux is formed with unkown variables to identify: \(\begin{equation} \begin{cases} w_i=F_{x1} \tanh(F_{x2} \frac{c_s}{c_l})/C_d\eta\\ \Phi=F_{x3}(w_i-0.042\dot\gamma (\sum c_id_i)^2 \frac{\partial c_l}{\partial z})\\ \end{cases} \end{equation}\)</p> <p align="center"> <img src="/assets/img/proj_pinn/pinn_dem.png" alt="Description of the image" style="width: 100%;"/> </p> <p>The variables are identified as: \(\begin{equation} \begin{cases} F_{x1}=2.1619\\ F_{x2}=1.3354\\ F_{x3}=2.4698\\ \end{cases} \end{equation}\)<br/> This implies a concentration dependence of force:</p> <p align="center"> <img src="/assets/img/proj_pinn/force.png" alt="Description of the image" style="width: 30%;"/> </p> <p align="center"> <img src="/assets/img/proj_pinn/pinn_dem_profiles.png" alt="Description of the image" style="width: 100%;"/> </p> <h3 id="dem-informed-nn---reduce-sample-size">DEM-informed NN - reduce sample size</h3> <p>DEM simulations (\(R_d=2,~R_\rho=1,~t=10\,s\)):</p> <p align="center"> <img src="/assets/img/proj_pinn/pinn_dem_reduced.png" alt="Description of the image" style="width: 100%;"/> </p> <p>The variables are identified as: \(\begin{equation} \begin{cases} F_{x1}=2.4664\\ F_{x2}=1.1263\\ F_{x3}=2.8693\\ \end{cases} \end{equation}\)</p> <p align="center"> <img src="/assets/img/proj_pinn/pinn_dem_profiles_reduced.png" alt="Description of the image" style="width: 100%;"/> </p> <h3 id="does-cubic-segregation-velocity-model-works-better">Does cubic segregation velocity model works better?</h3> \[\begin{equation} \begin{cases} w_i=F_{x1} c_l+ F_{x2}c_l^2+F_{x3}c_l^3\\ \Phi=F_{x4}(w_i-0.042\dot\gamma (\sum c_id_i)^2 \frac{\partial c_l}{\partial z})\\ \end{cases} \end{equation}\] <p>Cubic segregation velocity model cannot capture the DEM profiles.</p> <p align="center"> <img src="/assets/img/proj_pinn/pinn_dem_profiles_reduced1.png" alt="Description of the image" style="width: 100%;"/> </p>]]></content><author><name></name></author><category term="machine_learning"/><summary type="html"><![CDATA[PINN for 2D advection-diffusion-segregation equation]]></summary></entry><entry><title type="html">Frequently Used Tensor Operation</title><link href="https://19revey.github.io/blog/2024/torch/" rel="alternate" type="text/html" title="Frequently Used Tensor Operation"/><published>2024-01-07T12:00:00+00:00</published><updated>2024-01-07T12:00:00+00:00</updated><id>https://19revey.github.io/blog/2024/torch</id><content type="html" xml:base="https://19revey.github.io/blog/2024/torch/"><![CDATA[<h1 id="pytorch-tensor-manipulation-methods">PyTorch Tensor Manipulation Methods</h1> <p>This document summarizes commonly used PyTorch tensor manipulation functions, their purposes, and examples.</p> <h2 id="1-squeeze">1. <code class="language-plaintext highlighter-rouge">squeeze</code></h2> <p><strong>Function</strong>: Removes dimensions of size 1 from a tensor.</p> <p><strong>Example</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor_squeezed</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">()</span>  <span class="c1"># Removes all dimensions of size 1, resulting shape: (3, 4)
</span><span class="n">tensor_squeezed_dim</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Removes size 1 from the 0th dimension, resulting shape: (3, 4, 1)
</span></code></pre></div></div> <h2 id="2-view">2. <code class="language-plaintext highlighter-rouge">view</code></h2> <p><strong>Function</strong>: Reshapes a tensor without changing its data storage order.</p> <p><strong>Example</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor_reshaped</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># Reshapes to shape: (2, 8)
</span></code></pre></div></div> <h2 id="3-reshape">3. <code class="language-plaintext highlighter-rouge">reshape</code></h2> <p><strong>Function</strong>: Similar to <code class="language-plaintext highlighter-rouge">view</code>, reshapes a tensor, but may create a copy of the data if necessary.</p> <p><strong>Example</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor_reshaped</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># Reshapes to shape: (2, 8)
</span></code></pre></div></div> <h2 id="4-permute">4. <code class="language-plaintext highlighter-rouge">permute</code></h2> <p><strong>Function</strong>: Reorders the dimensions of a tensor.</p> <p><strong>Example</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor_permuted</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Changes dimension order, resulting shape: (4, 2, 3)
</span></code></pre></div></div> <h2 id="5-transpose">5. <code class="language-plaintext highlighter-rouge">transpose</code></h2> <p><strong>Function</strong>: Swaps two specified dimensions of a tensor.</p> <p><strong>Example</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor_transposed</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Swaps the 1st and 2nd dimensions, resulting shape: (2, 4, 3)
</span></code></pre></div></div> <h2 id="6-expand-and-expand_as">6. <code class="language-plaintext highlighter-rouge">expand</code> and <code class="language-plaintext highlighter-rouge">expand_as</code></h2> <p><strong>Function</strong>: Expands a tensor to match a specified shape without copying data, useful for broadcasting.</p> <p><strong>Example</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">tensor_expanded</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">expand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># Expands to shape: (4, 3)
</span></code></pre></div></div> <h2 id="7-repeat">7. <code class="language-plaintext highlighter-rouge">repeat</code></h2> <p><strong>Function</strong>: Duplicates tensor data and repeats it along specified dimensions.</p> <p><strong>Example</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tensor_repeated</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># Results in shape: (4, 6)
</span></code></pre></div></div> <h2 id="8-flatten">8. <code class="language-plaintext highlighter-rouge">flatten</code></h2> <p><strong>Function</strong>: Flattens a tensor into one dimension.</p> <p><strong>Example</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor_flattened</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()</span>  <span class="c1"># Results in shape: (24,)
</span></code></pre></div></div> <p>These tensor manipulation methods help reshape, reorder, and expand tensors efficiently to fit different computational needs and network architectures.</p>]]></content><author><name></name></author><category term="machine_learning"/><summary type="html"><![CDATA[PyTorch]]></summary></entry><entry><title type="html">Transformer using PyTorch</title><link href="https://19revey.github.io/blog/2023/transformer/" rel="alternate" type="text/html" title="Transformer using PyTorch"/><published>2023-07-11T12:57:00+00:00</published><updated>2023-07-11T12:57:00+00:00</updated><id>https://19revey.github.io/blog/2023/transformer</id><content type="html" xml:base="https://19revey.github.io/blog/2023/transformer/"><![CDATA[ <h2 style="color:purple;font-size: 2em;">Overview</h2> <p>Basic transformer with an encoder-decoder architecture for language translation models.</p> <ul> <li>Understanding transformers <ul> <li><a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">attention is all you need</a></li> </ul> </li> <li>Pytorch implementation <ul> <li><a href="https://pytorch.org/tutorials/beginner/transformer_tutorial.html">https://pytorch.org/tutorials/beginner/transformer_tutorial.html</a></li> <li><a href="https://www.kaggle.com/code/arunmohan003/transformer-from-scratch-using-pytorch">https://www.kaggle.com/code/arunmohan003/transformer-from-scratch-using-pytorch</a></li> </ul> </li> </ul> <p><a class="anchor" id="section1"></a></p> <h2 style="color:purple;font-size: 2em;">1. Introduction</h2> <p><img src="https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png" width="330" height="470" img="" style="float: right;"/></p> <ul> <li><a href="#section1">1. Introduction</a></li> <li><a href="#section2">2. Import libraries</a></li> <li><a href="#section3">3. Basic components</a> <ul> <li><a href="#section4">Word Embeddings</a></li> <li><a href="#section5">Positional Encoding</a></li> <li><a href="#section6">Self Attention</a></li> <li><a href="#section7">Transformer Block</a></li> </ul> </li> <li><a href="#section8">4. Encoder</a></li> <li><a href="#section9">5. Decoder</a></li> <li><a href="#section10">6. Transformer</a></li> </ul> <p><a class="anchor" id="section2"></a></p> <h2 style="color:purple;font-size: 2em;">2. Import Libraries</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">math</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="nf">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="p">(</span>
    <span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
    <span class="k">else</span> <span class="sh">"</span><span class="s">mps</span><span class="sh">"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
    <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span>
<span class="p">)</span>
</code></pre></div></div> <p><a class="anchor" id="section3"></a></p> <h2 style="color:purple;font-size: 2em;">3. Basic components</h2> <p><a class="anchor" id="section4"></a></p> <h2 style="color:purple;font-size: 1.5em;">Word Embeddings</h2> <p>Each word will be mapped to corresponding \(d_{model}=512\) embedding vector. Suppose we have batch_size of 32 and sequence_length of 10 (10 words). The the output will be Batch_size X sequence_length X embedding_dim (32X10X512).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Embedding</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            vocab_size: size of vocabulary
            embed_dim: dimension of embeddings, i.e. d_model
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Embedding</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            x: input vector, i.e. (batch, seq_len, vocab_size)
        Returns:
            out: embedding vector (batch, seq_len, embed_dim)
        </span><span class="sh">"""</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></div> <p><a class="anchor" id="section5"></a></p> <h2 style="color:purple;font-size: 1.5em;"> Positional Encoding</h2> \[PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})\] \[PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})\] <p>Here \(pos\) is the position of the word in the sentence, and \(i\) refers to position along embedding vector dimension.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">PositionalEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">max_seq_len</span><span class="p">,</span><span class="n">embed_model_dim</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            seq_len: length of input sequence
            embed_model_dim: demension of embedding, d_model
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">PositionalEmbedding</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_model_dim</span>

        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">embed_dim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">embed_dim</span><span class="p">,</span><span class="mi">2</span><span class="p">):</span>
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">embed_dim</span><span class="p">)))</span>
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="n">self</span><span class="p">.</span><span class="n">embed_dim</span><span class="p">)))</span>

        <span class="c1"># adding batch dimension for broadcasting
</span>        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> 

        <span class="c1"># register buffer in Pytorch -&gt;
</span>        <span class="c1"># If you have parameters in your model, which should be saved and restored in the state_dict,
</span>        <span class="c1"># but not trained by the optimizer, you should register them as buffers.
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">pe</span><span class="sh">'</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            x: input vector
        Returns:
            x: output
        </span><span class="sh">"""</span>
        <span class="c1"># make embeddings relatively larger
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">embed_dim</span><span class="p">)</span>
        <span class="c1">#add constant to embedding
</span>        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">].</span><span class="nf">detach</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div> <p><a class="anchor" id="section6"></a></p> <h2 style="color:purple; font-size: 1.5em;"> Self Attention</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            embed_dim: dimension of embeding vector output
            n_heads: number of self attention heads
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>    <span class="c1">#512 dim
</span>        <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>   <span class="c1">#8
</span>        <span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">embed_dim</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span><span class="p">)</span>   <span class="c1">#512/8 = 64  . each key,query, value will be of 64d
</span>       
        <span class="c1">#key,query and value matrixes    #64 x 64   
</span>        <span class="n">self</span><span class="p">.</span><span class="n">query_matrix</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span> <span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span> <span class="p">,</span><span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># single key matrix for all 8 keys #512x512
</span>        <span class="n">self</span><span class="p">.</span><span class="n">key_matrix</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span>  <span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">value_matrix</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span> <span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span> <span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_heads</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span> <span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">embed_dim</span><span class="p">)</span> 

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">key</span><span class="p">,</span><span class="n">query</span><span class="p">,</span><span class="n">value</span><span class="p">,</span><span class="n">mask</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>    <span class="c1">#batch_size x sequence_length x embedding_dim    # 32 x 10 x 512
</span>        
        <span class="sh">"""</span><span class="s">
        Args:
           key : key vector
           query : query vector
           value : value vector
           mask: mask for decoder
        
        Returns:
           output vector from multihead attention
        </span><span class="sh">"""</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">key</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">seq_length</span> <span class="o">=</span> <span class="n">key</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># query dimension can change in decoder during inference. 
</span>        <span class="c1"># so we cant take general seq_length
</span>        <span class="n">seq_length_query</span> <span class="o">=</span> <span class="n">query</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># 32x10x512
</span>        <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span><span class="p">)</span>  <span class="c1">#batch_size x sequence_length x n_heads x single_head_dim = (32x10x8x64)
</span>        <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length_query</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span><span class="p">)</span> <span class="c1">#(32x10x8x64)
</span>        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span><span class="p">)</span> <span class="c1">#(32x10x8x64)
</span>       
        <span class="n">k</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">key_matrix</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>       <span class="c1"># (32x10x8x64)
</span>        <span class="n">q</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">query_matrix</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>   
        <span class="n">v</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">value_matrix</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, n_heads, seq_len, single_head_dim)    # (32 x 8 x 10 x 64)
</span>        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, n_heads, seq_len, single_head_dim)
</span>        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, n_heads, seq_len, single_head_dim)
</span>       
        <span class="c1"># computes attention
</span>        <span class="c1"># adjust key for matrix multiplication
</span>        <span class="n">k_adjusted</span> <span class="o">=</span> <span class="n">k</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>  <span class="c1">#(batch_size, n_heads, single_head_dim, seq_ken)  #(32 x 8 x 64 x 10)
</span>        <span class="n">product</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k_adjusted</span><span class="p">)</span>  <span class="c1">#(32 x 8 x 10 x 64) x (32 x 8 x 64 x 10) = #(32x8x10x10)
</span>        
        <span class="c1"># fill those positions of product matrix as (-1e20) where mask positions are 0
</span>        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">product</span> <span class="o">=</span> <span class="n">product</span><span class="p">.</span><span class="nf">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nf">float</span><span class="p">(</span><span class="sh">"</span><span class="s">-1e20</span><span class="sh">"</span><span class="p">))</span>

        <span class="c1">#divising by square root of key dimension
</span>        <span class="n">product</span> <span class="o">=</span> <span class="n">product</span> <span class="o">/</span> <span class="n">math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span><span class="p">)</span> <span class="c1"># / sqrt(64)
</span>
        <span class="c1">#applying softmax
</span>        <span class="n">scores</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">product</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
 
        <span class="c1">#mutiply with value matrix
</span>        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>  <span class="c1">##(32x8x 10x 10) x (32 x 8 x 10 x 64) = (32 x 8 x 10 x 64) 
</span>        
        <span class="c1">#concatenated output
</span>        <span class="n">concat</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">).</span><span class="nf">contiguous</span><span class="p">().</span><span class="nf">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length_query</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">single_head_dim</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">n_heads</span><span class="p">)</span>  <span class="c1"># (32x8x10x64) -&gt; (32x10x8x64)  -&gt; (32,10,512)
</span>        
        <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">out</span><span class="p">(</span><span class="n">concat</span><span class="p">)</span> <span class="c1">#(32,10,512) -&gt; (32,10,512)
</span>       
        <span class="k">return</span> <span class="n">output</span>

</code></pre></div></div> <p><a class="anchor" id="section7"></a></p> <h2 style="color:purple; font-size: 1.5em;"> Transformer Block</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">TransformerBlock</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="sh">"""</span><span class="s">
        Args:
           embed_dim: dimension of the embedding
           expansion_factor: fator ehich determines output dimension of linear layer
           n_heads: number of attention heads
        
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">attention</span> <span class="o">=</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
                          <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="o">*</span><span class="n">embed_dim</span><span class="p">),</span>
                          <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
                          <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">expansion_factor</span><span class="o">*</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">key</span><span class="p">,</span><span class="n">query</span><span class="p">,</span><span class="n">value</span><span class="p">):</span>
        
        <span class="sh">"""</span><span class="s">
        Args:
           key: key vector
           query: query vector
           value: value vector
           norm2_out: output of transformer block
        
        </span><span class="sh">"""</span>
        
        <span class="n">attention_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">attention</span><span class="p">(</span><span class="n">key</span><span class="p">,</span><span class="n">query</span><span class="p">,</span><span class="n">value</span><span class="p">)</span>  <span class="c1">#32x10x512
</span>        <span class="n">attention_residual_out</span> <span class="o">=</span> <span class="n">attention_out</span> <span class="o">+</span> <span class="n">value</span>  <span class="c1">#32x10x512
</span>        <span class="n">norm1_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout1</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">norm1</span><span class="p">(</span><span class="n">attention_residual_out</span><span class="p">))</span> <span class="c1">#32x10x512
</span>
        <span class="n">feed_fwd_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">feed_forward</span><span class="p">(</span><span class="n">norm1_out</span><span class="p">)</span> <span class="c1">#32x10x512 -&gt; #32x10x2048 -&gt; 32x10x512
</span>        <span class="n">feed_fwd_residual_out</span> <span class="o">=</span> <span class="n">feed_fwd_out</span> <span class="o">+</span> <span class="n">norm1_out</span> <span class="c1">#32x10x512
</span>        <span class="n">norm2_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout2</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">norm2</span><span class="p">(</span><span class="n">feed_fwd_residual_out</span><span class="p">))</span> <span class="c1">#32x10x512
</span>
        <span class="k">return</span> <span class="n">norm2_out</span>

</code></pre></div></div> <p><a class="anchor" id="section8"></a></p> <h2 style="color:purple;font-size: 2em;"> 4. Encoder</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Args:
        seq_len : length of input sequence
        embed_dim: dimension of embedding
        num_layers: number of encoder layers
        expansion_factor: factor which determines number of linear layers in feed forward layer
        n_heads: number of heads in multihead attention
        
    Returns:
        out: output of the encoder
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">TransformerEncoder</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">embedding_layer</span> <span class="o">=</span> <span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">positional_encoder</span> <span class="o">=</span> <span class="nc">PositionalEmbedding</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span><span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">embed_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">embedding_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">positional_encoder</span><span class="p">(</span><span class="n">embed_out</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">out</span><span class="p">,</span><span class="n">out</span><span class="p">,</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>  <span class="c1">#32x10x512
</span></code></pre></div></div> <p><a class="anchor" id="section9"></a></p> <h2 style="color:purple;font-size: 2em;"> 5. Decoder</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DecoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">DecoderBlock</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="sh">"""</span><span class="s">
        Args:
           embed_dim: dimension of the embedding
           expansion_factor: fator ehich determines output dimension of linear layer
           n_heads: number of attention heads
        
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">attention</span> <span class="o">=</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">transformer_block</span> <span class="o">=</span> <span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">)</span>       
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span>
        
        <span class="sh">"""</span><span class="s">
        Args:
           key: key vector
           query: query vector
           value: value vector
           mask: mask to be given for multi head attention 
        Returns:
           out: output of transformer block
    
        </span><span class="sh">"""</span>
        <span class="c1">#we need to pass mask mask only to fst attention
</span>        <span class="n">attention</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">attention</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span> <span class="c1">#32x10x512
</span>        <span class="n">value</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">attention</span> <span class="o">+</span> <span class="n">x</span><span class="p">))</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">transformer_block</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">TransformerDecoder</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="sh">"""</span><span class="s">  
        Args:
           target_vocab_size: vocabulary size of taget
           embed_dim: dimension of embedding
           seq_len : length of input sequence
           num_layers: number of encoder layers
           expansion_factor: factor which determines number of linear layers in feed forward layer
           n_heads: number of heads in multihead attention
        
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">word_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">position_embedding</span> <span class="o">=</span> <span class="nc">PositionalEmbedding</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="nc">DecoderBlock</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> 
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
            <span class="p">]</span>

        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc_out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        
        <span class="sh">"""</span><span class="s">
        Args:
            x: input vector from target
            enc_out : output from encoder layer
            trg_mask: mask for decoder self attention
        Returns:
            out: output vector
        </span><span class="sh">"""</span>     
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">word_embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1">#32x10x512
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">position_embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1">#32x10x512
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
     
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">enc_out</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> 

        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc_out</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">out</span>

</code></pre></div></div> <p><a class="anchor" id="section10"></a></p> <h2 style="color:purple;font-size: 2em;"> 6. Transformer</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">src_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Transformer</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="sh">"""</span><span class="s">  
        Args:
           embed_dim:  dimension of embedding 
           src_vocab_size: vocabulary size of source
           target_vocab_size: vocabulary size of target
           seq_length : length of input sequence
           num_layers: number of encoder layers
           expansion_factor: factor which determines number of linear layers in feed forward layer
           n_heads: number of heads in multihead attention
        
        </span><span class="sh">"""</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">target_vocab_size</span> <span class="o">=</span> <span class="n">target_vocab_size</span>

        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">src_vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="o">=</span><span class="n">expansion_factor</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="n">n_heads</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">expansion_factor</span><span class="o">=</span><span class="n">expansion_factor</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="n">n_heads</span><span class="p">)</span>
        
    
    <span class="k">def</span> <span class="nf">make_trg_mask</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">trg</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            trg: target sequence
        Returns:
            trg_mask: target mask
        </span><span class="sh">"""</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">trg_len</span> <span class="o">=</span> <span class="n">trg</span><span class="p">.</span><span class="n">shape</span>
        <span class="c1"># returns the lower triangular part of matrix filled with ones
</span>        <span class="n">trg_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tril</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">trg_len</span><span class="p">,</span> <span class="n">trg_len</span><span class="p">))).</span><span class="nf">expand</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">trg_len</span><span class="p">,</span> <span class="n">trg_len</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">trg_mask</span>    

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">src</span><span class="p">,</span><span class="n">trg</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        for inference
        Args:
            src: input to encoder 
            trg: input to decoder
        out:
            out_labels : returns final prediction of sequence
        </span><span class="sh">"""</span>
        <span class="n">trg_mask</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">make_trg_mask</span><span class="p">(</span><span class="n">trg</span><span class="p">)</span>
        <span class="n">enc_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="n">out_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">batch_size</span><span class="p">,</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">src</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">src</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1">#outputs = torch.zeros(seq_len, batch_size, self.target_vocab_size)
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">trg</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">seq_len</span><span class="p">):</span> <span class="c1">#10
</span>            <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">decoder</span><span class="p">(</span><span class="n">out</span><span class="p">,</span><span class="n">enc_out</span><span class="p">,</span><span class="n">trg_mask</span><span class="p">)</span> <span class="c1">#bs x seq_len x vocab_dim
</span>            <span class="c1"># taking the last token
</span>            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>
     
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">out_labels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="n">out</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
          
        
        <span class="k">return</span> <span class="n">out_labels</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            src: input to encoder 
            trg: input to decoder
        out:
            out: final vector which returns probabilities of each target word
        </span><span class="sh">"""</span>
        <span class="n">trg_mask</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">make_trg_mask</span><span class="p">(</span><span class="n">trg</span><span class="p">)</span>
        <span class="n">enc_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
   
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">decoder</span><span class="p">(</span><span class="n">trg</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">,</span> <span class="n">trg_mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span>


</code></pre></div></div>]]></content><author><name></name></author><category term="machine_learning"/><summary type="html"><![CDATA[based on the paper "Attention is all you need"]]></summary></entry><entry><title type="html">U-Net using PyTorch</title><link href="https://19revey.github.io/blog/2023/unet/" rel="alternate" type="text/html" title="U-Net using PyTorch"/><published>2023-05-15T12:57:00+00:00</published><updated>2023-05-15T12:57:00+00:00</updated><id>https://19revey.github.io/blog/2023/unet</id><content type="html" xml:base="https://19revey.github.io/blog/2023/unet/"><![CDATA[ <p><a class="anchor" id="section1"></a></p> <h2 style="color:purple;font-size: 2em;">1. Introduction</h2> <p>The U-Net architecture is characterized by its unique symmetric U-shaped design, which consists of a contracting path (encoder) and an expansive path (decoder), connected by skip connections. This architecture enables the network to capture both local and global features while preserving spatial information, making it highly effective for pixel-level segmentation tasks.</p> <ul> <li><a href="https://arxiv.org/pdf/1505.04597">Reference: U-Net: Convolutional Networks for Biomedical Image Segmentation</a> <ul> <li>Weighted loss for seperation of touching objects of the same class</li> <li>Overalp-tile strategy for arbitrary large images</li> </ul> </li> </ul> <p><img src="https://miro.medium.com/v2/resize:fit:1400/1*f7YOaE4TWubwaFF7Z1fzNw.png" width="700" height="457" img="" style="float: top;"/></p> <p><a class="anchor" id="section3"></a></p> <h2 style="color:purple;font-size: 2em;">2. Components</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DoubleConv</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">(convolution =&gt; [BN] =&gt; ReLU) * 2</span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mid_channels</span><span class="p">:</span>
            <span class="n">mid_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">double_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">mid_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">mid_channels</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">mid_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">double_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Down</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Downscaling with maxpool then double conv</span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">maxpool_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="nc">DoubleConv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">maxpool_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Up</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Upscaling then double conv</span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">bilinear</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="c1"># if bilinear, use the normal convolutions to reduce the number of channels
</span>        <span class="k">if</span> <span class="n">bilinear</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">bilinear</span><span class="sh">'</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">conv</span> <span class="o">=</span> <span class="nc">DoubleConv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">in_channels</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ConvTranspose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">conv</span> <span class="o">=</span> <span class="nc">DoubleConv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">up</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="c1"># input is CHW
</span>        <span class="n">diffY</span> <span class="o">=</span> <span class="n">x2</span><span class="p">.</span><span class="nf">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">x1</span><span class="p">.</span><span class="nf">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">diffX</span> <span class="o">=</span> <span class="n">x2</span><span class="p">.</span><span class="nf">size</span><span class="p">()[</span><span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">x1</span><span class="p">.</span><span class="nf">size</span><span class="p">()[</span><span class="mi">3</span><span class="p">]</span>

        <span class="n">x1</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="p">[</span><span class="n">diffX</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">diffX</span> <span class="o">-</span> <span class="n">diffX</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                        <span class="n">diffY</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">diffY</span> <span class="o">-</span> <span class="n">diffY</span> <span class="o">//</span> <span class="mi">2</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">x2</span><span class="p">,</span> <span class="n">x1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">OutConv</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">OutConv</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

</code></pre></div></div> <p><a class="anchor" id="section8"></a></p> <h2 style="color:purple;font-size: 2em;"> 3. UNet</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">UNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">bilinear</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">UNet</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_channels</span> <span class="o">=</span> <span class="n">n_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="n">n_classes</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bilinear</span> <span class="o">=</span> <span class="n">bilinear</span>

        <span class="n">self</span><span class="p">.</span><span class="n">inc</span> <span class="o">=</span> <span class="p">(</span><span class="nc">DoubleConv</span><span class="p">(</span><span class="n">n_channels</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">down1</span> <span class="o">=</span> <span class="p">(</span><span class="nc">Down</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">down2</span> <span class="o">=</span> <span class="p">(</span><span class="nc">Down</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">down3</span> <span class="o">=</span> <span class="p">(</span><span class="nc">Down</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
        <span class="n">factor</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">bilinear</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">down4</span> <span class="o">=</span> <span class="p">(</span><span class="nc">Down</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span> <span class="o">//</span> <span class="n">factor</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">up1</span> <span class="o">=</span> <span class="p">(</span><span class="nc">Up</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span> <span class="o">//</span> <span class="n">factor</span><span class="p">,</span> <span class="n">bilinear</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">up2</span> <span class="o">=</span> <span class="p">(</span><span class="nc">Up</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span> <span class="o">//</span> <span class="n">factor</span><span class="p">,</span> <span class="n">bilinear</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">up3</span> <span class="o">=</span> <span class="p">(</span><span class="nc">Up</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span> <span class="o">//</span> <span class="n">factor</span><span class="p">,</span> <span class="n">bilinear</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">up4</span> <span class="o">=</span> <span class="p">(</span><span class="nc">Up</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">bilinear</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">outc</span> <span class="o">=</span> <span class="p">(</span><span class="nc">OutConv</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">inc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">down1</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">down2</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
        <span class="n">x4</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">down3</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>
        <span class="n">x5</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">down4</span><span class="p">(</span><span class="n">x4</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">up1</span><span class="p">(</span><span class="n">x5</span><span class="p">,</span> <span class="n">x4</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">up2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x3</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">up3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">up4</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">outc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

    <span class="k">def</span> <span class="nf">use_checkpointing</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">inc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">inc</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">down1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">down1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">down2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">down2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">down3</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">down3</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">down4</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">down4</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">up1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">up1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">up2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">up2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">up3</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">up3</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">up4</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">up4</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">outc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">outc</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="machine_learning"/><summary type="html"><![CDATA[based on the paper "U-Net Convolutional Networks for Biomedical Image Segmentation"]]></summary></entry><entry><title type="html">Improve resume using LLM</title><link href="https://19revey.github.io/blog/2023/resume/" rel="alternate" type="text/html" title="Improve resume using LLM"/><published>2023-01-02T17:39:00+00:00</published><updated>2023-01-02T17:39:00+00:00</updated><id>https://19revey.github.io/blog/2023/resume</id><content type="html" xml:base="https://19revey.github.io/blog/2023/resume/"><![CDATA[<h2 id="the-app-is-hosted-on-streamlit-cloud-httpsllmresumestreamlitapp">The app is hosted on streamlit cloud: <a href="https://llmresume.streamlit.app/">https://llmresume.streamlit.app/</a></h2> <p><br/></p> <h3 id="paste-the-job-description-and-upload-your-resume-to-obtain-insights-including">Paste the job description and upload your resume to obtain insights, including:</h3> <ul> <li>an overall match percentage;</li> <li>key skills that should be highlighted in your resume;</li> <li>identification of keywords from the job description that are not present in your resume.</li> </ul> <p><br/></p> <h4 id="to-run-it-locally">To run it locally</h4> <p>Make sure docker is installed, otherwise run installdocker.sh first:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sh installdocker.sh
</code></pre></div></div> <p>Download source code:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/19revey/LLM_resume.git
</code></pre></div></div> <p>Build docker image and start container:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker compose up
</code></pre></div></div>]]></content><author><name></name></author><category term="machine_learning"/><summary type="html"><![CDATA[improve resume based on job description using Google Gemini Pro]]></summary></entry><entry><title type="html">Running VScode an IPad</title><link href="https://19revey.github.io/blog/2022/ipad/" rel="alternate" type="text/html" title="Running VScode an IPad"/><published>2022-05-16T01:57:00+00:00</published><updated>2022-05-16T01:57:00+00:00</updated><id>https://19revey.github.io/blog/2022/ipad</id><content type="html" xml:base="https://19revey.github.io/blog/2022/ipad/"><![CDATA[<h1 align="left" style="color:purple;font-size: 2em;">Overview</h1> <p>The iPad pro boasts a powerful chip, but its productivity features remain somewhat limited. While iPadOS doesn’t currently support VSCode, there are several workarounds to enable coding on the iPad, taking advantage of its exceptional touch support and stunning HDR screen.</p> <p>https://github.com/coder/code-server</p> <p>https://docs.linuxserver.io/images/docker-code-server/</p> <p><br/></p> <p><a class="anchor" id="section1"></a></p> <h2 style="color:purple;font-size: 2em;">Setting up docker running code-server</h2> <div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="s"> lscr.io/linuxserver/code-server:latest</span>

<span class="k">ENV</span><span class="s"> DEBIAN_FRONTEND=noninteractive </span>

<span class="k">RUN </span>apt-get update <span class="o">&amp;&amp;</span> apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="se">\
</span>    build-essential <span class="se">\
</span>    software-properties-common <span class="se">\
</span>    git <span class="se">\
</span>    python3-pip <span class="se">\
</span>    <span class="o">&amp;&amp;</span> apt-get clean <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> /var/lib/apt/lists/<span class="k">*</span> /var/cache/apt/archives/<span class="k">*</span>

<span class="k">WORKDIR</span><span class="s"> /app</span>

<span class="k">COPY</span><span class="s"> . /app</span>

<span class="k">RUN </span>pip <span class="nb">install</span> <span class="nt">--upgrade</span> pip
<span class="k">RUN </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt

</code></pre></div></div> <p>Automated building and running using Docker Compose</p> <div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code>services:

  code-server:
    # image: lscr.io/linuxserver/code-server:latest
    build: .
    container_name: code-server
    runtime: nvidia
    environment:

      - PUID=1000

      - PGID=1000

      - TZ=Etc/UTC

      - PASSWORD= #optional

      - HASHED_PASSWORD= #optional

      - SUDO_PASSWORD= #optional

      - SUDO_PASSWORD_HASH= #optional

      - PROXY_DOMAIN=code-server.my.domain <span class="c">#optional</span>

      - DEFAULT_WORKSPACE=/config/workspace <span class="c">#optional</span>

      - NVIDIA_VISIBLE_DEVICES=all
    
    volumes:
      - /path/to/appdata/config:/config

      - ../../:/config/workspace
    ports:
      - 8443:8443
</code></pre></div></div>]]></content><author><name></name></author><category term="machine_learning"/><summary type="html"><![CDATA[taking advantage of IPad's exceptional touch support and stunning tandem OLED screen]]></summary></entry><entry><title type="html">Compare classification models</title><link href="https://19revey.github.io/blog/2022/ml_classification/" rel="alternate" type="text/html" title="Compare classification models"/><published>2022-05-01T12:57:00+00:00</published><updated>2022-05-01T12:57:00+00:00</updated><id>https://19revey.github.io/blog/2022/ml_classification</id><content type="html" xml:base="https://19revey.github.io/blog/2022/ml_classification/"><![CDATA[<h3 id="compare-different-classification-models-using-the-titanic-disaster-data">Compare different classification models using the titanic disaster data</h3> <p><br/></p> <table> <thead> <tr> <th>Model</th> <th>F1 score</th> </tr> </thead> <tbody> <tr> <td>Random Forest</td> <td>0.7917</td> </tr> <tr> <td>Logistic Regression</td> <td>0.7586</td> </tr> <tr> <td>Neural Network</td> <td>0.7536</td> </tr> <tr> <td>K-Neighbors</td> <td>0.7500</td> </tr> <tr> <td>Naive Bayes</td> <td>0.7436</td> </tr> <tr> <td>XGBClassifier</td> <td>0.7347</td> </tr> <tr> <td>Decision Tree</td> <td>0.7020</td> </tr> </tbody> </table> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/ml_compare.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="machine_learning"/><summary type="html"><![CDATA[based on the titanic disaster data]]></summary></entry><entry><title type="html">Compare regression models</title><link href="https://19revey.github.io/blog/2022/ml_regression/" rel="alternate" type="text/html" title="Compare regression models"/><published>2022-05-01T12:57:00+00:00</published><updated>2022-05-01T12:57:00+00:00</updated><id>https://19revey.github.io/blog/2022/ml_regression</id><content type="html" xml:base="https://19revey.github.io/blog/2022/ml_regression/"><![CDATA[<h3 id="compare-different-regression-models-using-the-alien-age-data">Compare different regression models using the alien age data</h3> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/compare_regression.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="machine_learning"/><summary type="html"><![CDATA[based on the alien age data]]></summary></entry></feed>